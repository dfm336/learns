# 控制器
Kafka集群中会有一个或多个Broker，其中一个 broker 会被选举为 控制器（Kafka Controller),
它负责 管理 整个集群中的 所有分区 和 副本的状态。
- 当某个分区的 Leader副本出现故障时，控制器 负责 为该分区 选举出 新的Leader副本。
- 当检测到 某个分区的 ISR集合 发生变化 时，由 控制器 负责 通知 所有broker 更新 元数据信息
- 当使用 kafka-topic.sh 脚本为 某个topic 新增 分区时，控制器负责 分区的重新分配

## 控制器的选举&异常恢复

Kafka Controller的 选举工作 依赖于 Zookeeper， 成功竞选的 broker 会在  ZK中
创建一个 **临时节点**（ /controller) 。这个临时节点 包含的 内容有： 
- brokerId： 成功竞选为 controller 的 broker id 
- version ：在目前版本 固定为 1
- timestamp ： 竞选称为 controller 时的  时间戳


**在任意时刻，集群有且仅有 一个 控制器**
> 每个broker 在集群启动的时候，都会去 尝试读取 zk中  /controller 节点的 brokerId 的值。
> 如果 该值 不是 -1， 就标识 已经有 其他 broker 竞选为 控制器了，当前 节点 则会放弃 竞选；
> 如果 zk 中不存在 /controller 节点，或者 数据异常， 那么 该节点 就会尝试 去创建 /controller 节点。
> 
>当前节点去 创建 /controller 节点的时候， 也可能有 其他 broker去创建 这个节点。 只有创建成功的那个
> broker 才会称为 控制器， 而创建失败的 broker 竞选失败，会在内存中 保留 当前控制器的 brokerID，
> 这个 值 也可称为 activeControllerId
> 
> 利用了 zk的 节点不可重复特性，同一时刻，多态机器创建同一节点，只有一个能成功。


zk中还有一个 与控制器 有关的 /controller_epoch  持久节点。 这个节点存放的是 **一个整型的controller_epoch值**
用来记录 控制器 发生变更的次数， 即：记录当前的控制器是 第几代
>ontroller_epoch 的初始值为 1，即集群中第一个控制器的纪元为 1，
> 当控制器发生变更 时，每选出一个新的控制器就将该字段值加  1
> 
> 每个和控制器交互的请求都会携带 controller_epoch 这个宇段，
> 如果请求的 controller_epoch 值小于内存中的 controller_epoch 值， 则认为这个请求是向己经过期的控制器所发送的请求，那么这个请求会被认定为无效的请求。 
> 如果请求的 controller_epoch 值大于内存中的 controller_epoch 值，那么说明 已经有 新的控制器当选了 。
>  Kafka 通过 controller epoch 来保证控制器的唯一性， 进而保证 相关操作的 唯一性


具备控制器身份的broker需要比其他普通的broker多一份职责， 具体细节如下:
- 监听**分区**相关变化
  - 为 ZooKeeper 中的/admin/reassign_partitions 节点注册 PartitionReassignmentHandler， 用来处理**分区重分配的动作
  - 为 ZooKeeper 中的 /isr_change_notification 节点注册 IsrChangeNotificetionHandler，用来处理 **ISR 集合变更** 的动作
  - 为 ZooKeeper 中的 /admin/preferred-replica-election 节 点添加 PreferredReplicaElectionHandler，用来处理**优先副本 的选举**动作。
- 监听**主题**相关的变化
  - 为 ZooKeeper 中的 /brokers/topics 节 点添 加 TopicChangeHandler， 用来 处理**主题增减 的 变 化**
  - 为 ZooKeeper 中 的 /admin/delete_topics 节点添加 TopicDeletionHandler，用来处理**删除主题 的动作**
- 监听**broker**相关的变化
  - 为 ZooKeeper中的/brokers/ids 节点添加 BrokerChangeHandler, 用来处理 **broker增减的变化**。
- 从 ZooKeeper 中读取获取当前所有与主题、分区及 broker 有关的信息并进行相应的管 理。
  对所 有主题 对 应 的 ZooKeeper 中的 /brokers/topics/<topic>节 点添 加 PartitionModificationsHandler， 用来**监听主题中的分区分配变化** 。
- 启动 并**管理 分区状态机 和 副本状态机**
- 更新 集群的 元数据 信息
- 如果参数 auto.leader.rebalance.enable 设置为 true，则还会开启一个名为 “auto-leader-rebalance-task” 的定时任务来负责维护**分区的优先副本的均衡**。


> 某个 broker选举成功，称为 Controller之后， 会读取 ZK中 各个节点的数据，来初始化 上下文信息（Controller Context)
> ,并且 需要管理 这些上下文信息。 也就是  维护这个 Controller Context 信息， 并同步到 其他 broker
> 
> 也就是说， 这个 Controller Context 是一个 共享信息。那么 就会存在 多线程之间的 线程安全问题。
> 如果单纯 用 锁机制 来实现，那么整体 性能肯定 大打折扣。

针对 （Controller Context) 的 线程安全问题， Kafka采用了 **使用单线程基于 事件队列的模型**，将每个
事件 都做一层封装， 然后 按照事件的 先后顺序  暂存到 LinkedBlockingQueue 中。 最后 使用一个 专用的
线程（ControllerEventThread) 按照 FIFO 的原则顺序 处理事件。 这样 也就不需要 锁机制 来 维护线程安全了
![img.png](使用单线程基于%20事件队列的模型.png)

在目前的新版本的设计中，只有 Kafka Controller 在 ZooKeeper 上注册相应的监昕器，
其 他的 broker 极少需要再监 听 ZooKeeper 中的 数据变化 ， 这样省去了很多不必要的麻烦。

不过每个 broker还是会对/controller 节点添加监听器， 
以 此来监 昕此节点的 数据变化 (ControllerCbangeHandler) 


# 优雅关闭
 kill -9 这种 “强杀”的方式并不够优雅， 它并不会等待 Kafka 进程合理关闭一些资源及保存一些运行数据之后再实施关闭动作

Kafka 自身提供了 一 个脚本工具，就是存放在其 bin 目录 下的 kafka-server-stop.sh

使用kill -s TERM PIDS 或 kill 15 PIDS的方式来关闭进程，注意千万 不要使用 kill - 9 的方式。

为什么这样关闭的方式会是优雅的? Kafka 服务入口程序中有一个名为“ kafka-shutdown­ hock”的关闭钩子 ， 
待 Kafka 进程捕获终止信号的时候会执行这个关闭钩子中的内容，
其中除 了
- 正常关闭一些必要的资源，还会执行一 个 控制关闭( ControlledShutdown)的 动 作 。 
- 使用 ControlledShutdown的方式关闭 Kafka有两个优点:
  - 一是可以让消息完全同步到磁盘上，在服务 下次重新上线时不需要进行日志的恢复操作 ; 
  - 二是 ControllerShutdown 在关 闭服务之前，会对 其上的 leader 副本进行迁移，这样就可以减少分区的不可用时间 
  

# 分区leader 的选举
分区 leader副本的选举由控制器负责具体实施。

- 创建分区(创建主题或增加分区都有创 建分区的动作)
- 分区上线(比如分区中原先的 leader 副本下线，此时分区需要选举一个新的 leader 上 线来对外提供服务)的时候都需要执行 leader 的选举动作
>创建分区 和 分区上线 都是让本分区的能正常提供服务，刚开始没有leader副本，所以需要选举 leader 副本

对应的选举策略为 OftlinePartitionLeaderElectionStrategy。 
这种策略的基本思路是按照 **AR 集合中副本的顺序查找 第一个存活的副本，并且这个副本在 ISR集合中**。 
**一个分区的 AR集合在分配的时候就被指定， 并且只要不发生重分配的情况，集合内部副本的顺序是保持不变的**，
而分区的 **ISR 集合中副本 的顺序可能会改变**。

>注意这里是根据AR的顺序而不是ISR的顺序进行选举的.
> 如果ISR中没有可用的副本，那么可以通过设置 参数 unclean.leader.election.enable 默认false. 
> 设为 true 则允许 从 非ISR 集合汇总 选出 Leader 副本，AR中 找到第一个 存活就好。


- 分区进行重分配时 也会进行 Leader的选举动作。ReassignPartiti。此eaderElectionStrategy策略：从分配的AR列表中找到第一个存活的副本，且这个副本在ISR中。

>  当 Kafka 集群进行分区重分配（partition reassignment）时，通常会涉及到副本的增加、删除或移动，
> 这个过程中可能会导致某些分区的 leader 副本不再适合处理该分区的请求，需要重新进行 leader 副本选举，选举出一个新的 leader 副本来处理该分区的请求。因此，在 Kafka 进行分区重分配时，通常会涉及到 leader 副本的选举操作。
>q: ReassignPartiti。此eaderElectionStrategy跟 正常的  OftlinePartitionLeaderElectionStrategy 策略 有什么不同吗？
> A:

- 当某个broker优雅关闭（也就是执行ControllerShutDown），位于该节点的Leader副本都会下线，所以与此
对应的分区 都需要 执行 leader的选举。
>与此对应 的选举策略( ControlledShutdownPartitionLeaderElectionStrategy)为 : 从 AR 列表中找到第一个存活的副本，且这个副本在目前的 ISR列表中，与此同时还要确保这 个副本不处于正在被关闭的节点上 。  


